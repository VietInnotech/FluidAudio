#if os(macOS)
import AVFoundation
import CoreML
import FluidAudio
import Foundation

/// Earnings22 benchmark using TDT for transcription + CTC for keyword spotting.
/// TDT provides low WER transcription, CTC provides high recall dictionary detection.
public enum CtcEarningsBenchmark {

    /// Keywords mode for vocabulary selection
    /// - chunk: Use dictionary.txt (chunk-level keywords) for both vocabulary and scoring
    /// - file: Use keywords.txt (file-level keywords) for vocabulary, dictionary.txt for scoring
    public enum KeywordsMode: String {
        case chunk = "chunk"
        case file = "file"
    }

    /// Default CTC model directory for a given variant
    private static func defaultCtcModelPath(for variant: CtcModelVariant) -> String? {
        let modelPath = CtcModels.defaultCacheDirectory(for: variant)
        if FileManager.default.fileExists(atPath: modelPath.path) {
            return modelPath.path
        }
        return nil
    }

    /// Default data directory (from download command)
    private static func defaultDataDir() -> String? {
        let dataDir = DatasetDownloader.getEarnings22Directory().appendingPathComponent("test-dataset")
        if FileManager.default.fileExists(atPath: dataDir.path) {
            return dataDir.path
        }
        return nil
    }

    public static func runCLI(arguments: [String]) async {
        // Check for help
        if arguments.contains("--help") || arguments.contains("-h") {
            printUsage()
            return
        }

        // Parse arguments
        var dataDir: String? = nil
        var outputFile = "ctc_earnings_benchmark.json"
        var maxFiles: Int? = nil
        var ctcModelPath: String? = nil
        var singleFileId: String? = nil
        // Note: Using v2 by default because v3 has issues with certain audio files
        // (returns empty transcription for ~7 files in Earnings22 dataset)
        var tdtVersion: AsrModelVersion = .v2
        var autoDownload = false
        var keywordsMode: KeywordsMode = .chunk
        // CTC model variant: 110m (hybrid, blank-dominant) or 06b (pure CTC, better for greedy)
        var ctcVariant: CtcModelVariant = .ctc110m
        // Constrained CTC rescoring is enabled by default
        var useConstrainedCTC = true

        var i = 0
        while i < arguments.count {
            switch arguments[i] {
            case "--data-dir":
                if i + 1 < arguments.count {
                    dataDir = arguments[i + 1]
                    i += 1
                }
            case "--output", "-o":
                if i + 1 < arguments.count {
                    outputFile = arguments[i + 1]
                    i += 1
                }
            case "--max-files":
                if i + 1 < arguments.count {
                    maxFiles = Int(arguments[i + 1])
                    i += 1
                }
            case "--ctc-model":
                if i + 1 < arguments.count {
                    ctcModelPath = arguments[i + 1]
                    i += 1
                }
            case "--file-id":
                if i + 1 < arguments.count {
                    singleFileId = arguments[i + 1]
                    i += 1
                }
            case "--tdt-version":
                if i + 1 < arguments.count {
                    if arguments[i + 1] == "v2" || arguments[i + 1] == "2" {
                        tdtVersion = .v2
                    }
                    i += 1
                }
            case "--auto-download":
                autoDownload = true
            case "--keywords":
                if i + 1 < arguments.count {
                    if let mode = KeywordsMode(rawValue: arguments[i + 1].lowercased()) {
                        keywordsMode = mode
                    } else {
                        print("WARNING: Invalid keywords mode '\(arguments[i + 1])'. Using 'chunk'.")
                    }
                    i += 1
                }
            case "--ctc-variant":
                if i + 1 < arguments.count {
                    let variant = arguments[i + 1].lowercased()
                    if variant == "06b" || variant == "0.6b" {
                        ctcVariant = .ctc06b
                    } else if variant == "110m" {
                        ctcVariant = .ctc110m
                    } else {
                        print("WARNING: Invalid CTC variant '\(arguments[i + 1])'. Using '110m'.")
                    }
                    i += 1
                }
            case "--no-constrained-ctc":
                useConstrainedCTC = false
            default:
                break
            }
            i += 1
        }

        // Use defaults if not specified
        if dataDir == nil {
            dataDir = defaultDataDir()
        }
        if ctcModelPath == nil {
            ctcModelPath = defaultCtcModelPath(for: ctcVariant)
        }

        // Handle auto-download for dataset
        if autoDownload && dataDir == nil {
            print("üì• Downloading earnings22-kws dataset...")
            await DatasetDownloader.downloadEarnings22KWS(force: false)
            dataDir = defaultDataDir()
        }

        print("Earnings Benchmark (TDT transcription + CTC keyword spotting)")
        print("  Data directory: \(dataDir ?? "not found")")
        print("  Output file: \(outputFile)")
        print("  TDT version: \(tdtVersion == .v2 ? "v2" : "v3")")
        print("  CTC variant: \(ctcVariant.displayName)")
        print("  CTC model: \(ctcModelPath ?? "not found")")
        print("  Keywords mode: \(keywordsMode.rawValue)")

        guard let finalDataDir = dataDir else {
            print("ERROR: Data directory not found")
            print("üí° Download with: fluidaudio download --dataset earnings22-kws")
            print("   Or specify: --data-dir <path>")
            printUsage()
            return
        }

        guard let modelPath = ctcModelPath else {
            print("ERROR: CTC model not found")
            print("üí° Download \(ctcVariant.repo.folderName) model to:")
            print("   \(CtcModels.defaultCacheDirectory(for: ctcVariant).path)/")
            print("   Or specify: --ctc-model <path>")
            print("   Or use different variant: --ctc-variant 110m|06b")
            printUsage()
            return
        }

        let dataDirResolved = finalDataDir

        do {
            // Load TDT models for transcription
            print("Loading TDT models (\(tdtVersion == .v2 ? "v2" : "v3")) for transcription...")
            let tdtModels = try await AsrModels.downloadAndLoad(version: tdtVersion)
            let asrManager = AsrManager(config: .default)
            try await asrManager.initialize(models: tdtModels)
            print("TDT models loaded successfully")

            // Load CTC models for keyword spotting
            print("Loading CTC models from: \(modelPath)")
            let modelDir = URL(fileURLWithPath: modelPath)
            let ctcModels = try await CtcModels.loadDirect(from: modelDir, variant: ctcVariant)
            print(
                "Loaded CTC vocabulary with \(ctcModels.vocabulary.count) tokens, variant: \(ctcModels.variant.displayName)"
            )

            // Create keyword spotter
            let vocabSize = ctcModels.vocabulary.count
            let blankId = vocabSize  // Blank is at index = vocab_size
            let spotter = CtcKeywordSpotter(models: ctcModels, blankId: blankId)
            print("Created CTC spotter with blankId=\(blankId)")

            // Collect test files
            let dataDirURL = URL(fileURLWithPath: dataDirResolved)
            let fileIds: [String]

            if let singleId = singleFileId {
                // Single file mode - verify the file exists
                let wavFile = dataDirURL.appendingPathComponent("\(singleId).wav")
                let dictFile = dataDirURL.appendingPathComponent("\(singleId).dictionary.txt")

                guard FileManager.default.fileExists(atPath: wavFile.path) else {
                    print("ERROR: WAV file not found: \(wavFile.path)")
                    return
                }
                guard FileManager.default.fileExists(atPath: dictFile.path) else {
                    print("ERROR: Dictionary file not found: \(dictFile.path)")
                    return
                }

                fileIds = [singleId]
                print("Single file mode: \(singleId)")
            } else {
                fileIds = try collectFileIds(from: dataDirURL, maxFiles: maxFiles)
            }

            if fileIds.isEmpty {
                print("ERROR: No test files found in \(dataDirResolved)")
                return
            }

            print("Processing \(fileIds.count) test file\(fileIds.count == 1 ? "" : "s")...")

            var results: [[String: Any]] = []
            var totalWer = 0.0
            var totalDictChecks = 0
            var totalDictFound = 0
            var totalAudioDuration = 0.0
            var totalProcessingTime = 0.0
            // Precision/Recall metrics: word found AND in correct position
            var totalTruePositives = 0  // In reference AND in hypothesis
            var totalFalsePositives = 0  // In hypothesis but NOT in reference
            var totalFalseNegatives = 0  // In reference but NOT in hypothesis

            for (index, fileId) in fileIds.enumerated() {
                if let result = try await processFile(
                    fileId: fileId,
                    dataDir: dataDirURL,
                    asrManager: asrManager,
                    ctcModels: ctcModels,
                    spotter: spotter,
                    keywordsMode: keywordsMode,
                    useConstrainedCTC: useConstrainedCTC
                ) {
                    results.append(result)
                    totalWer += result["wer"] as? Double ?? 0
                    totalDictChecks += result["dictTotal"] as? Int ?? 0
                    totalDictFound += result["dictFound"] as? Int ?? 0
                    totalAudioDuration += result["audioLength"] as? Double ?? 0
                    totalProcessingTime += result["processingTime"] as? Double ?? 0
                    totalTruePositives += result["truePositives"] as? Int ?? 0
                    totalFalsePositives += result["falsePositives"] as? Int ?? 0
                    totalFalseNegatives += result["falseNegatives"] as? Int ?? 0

                    let wer = result["wer"] as? Double ?? 0
                    let dictFound = result["dictFound"] as? Int ?? 0
                    let dictTotal = result["dictTotal"] as? Int ?? 0
                    let indexStr = String(format: "[%3d/%d]", index + 1, fileIds.count)
                    let paddedId = fileId.padding(toLength: 25, withPad: " ", startingAt: 0)
                    print(
                        "\(indexStr) \(paddedId) WER: \(String(format: "%5.1f", wer))%  Dict: \(dictFound)/\(dictTotal)"
                    )
                }
            }

            // Calculate summary
            let avgWer = results.isEmpty ? 0.0 : totalWer / Double(results.count)
            let dictRate = totalDictChecks > 0 ? Double(totalDictFound) / Double(totalDictChecks) * 100 : 0

            // Precision/Recall/F-score for vocabulary words
            let precision =
                (totalTruePositives + totalFalsePositives) > 0
                ? Double(totalTruePositives) / Double(totalTruePositives + totalFalsePositives) : 0
            let recall =
                (totalTruePositives + totalFalseNegatives) > 0
                ? Double(totalTruePositives) / Double(totalTruePositives + totalFalseNegatives) : 0
            let fscore =
                (precision + recall) > 0
                ? 2 * precision * recall / (precision + recall) : 0

            // Print summary
            print("\n" + String(repeating: "=", count: 60))
            print("EARNINGS22 BENCHMARK (TDT + CTC)")
            print(String(repeating: "=", count: 60))
            print("Model: \(modelPath)")
            print("Total tests: \(results.count)")
            print("Average WER: \(String(format: "%.2f", avgWer))%")
            print("Dict Pass (Recall): \(totalDictFound)/\(totalDictChecks) (\(String(format: "%.1f", dictRate))%)")
            print(
                "Vocab Precision: \(String(format: "%.1f", precision * 100))% (TP=\(totalTruePositives), FP=\(totalFalsePositives))"
            )
            print(
                "Vocab Recall: \(String(format: "%.1f", recall * 100))% (TP=\(totalTruePositives), FN=\(totalFalseNegatives))"
            )
            print("Vocab F-score: \(String(format: "%.1f", fscore * 100))%")
            print("Total audio: \(String(format: "%.1f", totalAudioDuration))s")
            print("Total processing: \(String(format: "%.1f", totalProcessingTime))s")
            if totalProcessingTime > 0 {
                print("RTFx: \(String(format: "%.2f", totalAudioDuration / totalProcessingTime))x")
            }
            print(String(repeating: "=", count: 60))

            // Save to JSON
            let summaryDict: [String: Any] = [
                "totalTests": results.count,
                "avgWer": round(avgWer * 100) / 100,
                "dictPass": totalDictFound,
                "dictTotal": totalDictChecks,
                "dictRate": round(dictRate * 100) / 100,
                "vocabTruePositives": totalTruePositives,
                "vocabFalsePositives": totalFalsePositives,
                "vocabFalseNegatives": totalFalseNegatives,
                "vocabPrecision": round(precision * 1000) / 1000,
                "vocabRecall": round(recall * 1000) / 1000,
                "vocabFscore": round(fscore * 1000) / 1000,
                "totalAudioDuration": round(totalAudioDuration * 100) / 100,
                "totalProcessingTime": round(totalProcessingTime * 100) / 100,
            ]

            let output: [String: Any] = [
                "model": modelPath,
                "keywordsMode": keywordsMode.rawValue,
                "summary": summaryDict,
                "results": results,
            ]

            let jsonData = try JSONSerialization.data(withJSONObject: output, options: [.prettyPrinted, .sortedKeys])
            try jsonData.write(to: URL(fileURLWithPath: outputFile))
            print("\nResults written to: \(outputFile)")

        } catch {
            print("ERROR: Benchmark failed: \(error)")
        }
    }

    private static func collectFileIds(from dataDir: URL, maxFiles: Int?) throws -> [String] {
        var fileIds: [String] = []
        let suffix = ".dictionary.txt"

        let fileManager = FileManager.default
        let contents = try fileManager.contentsOfDirectory(at: dataDir, includingPropertiesForKeys: nil)

        for url in contents.sorted(by: { $0.path < $1.path }) {
            let name = url.lastPathComponent
            if name.hasSuffix(suffix) {
                let data = try? Data(contentsOf: url)
                if let data = data, !data.isEmpty {
                    let fileId = String(name.dropLast(suffix.count))
                    fileIds.append(fileId)
                }
            }
        }

        if let maxFiles = maxFiles {
            return Array(fileIds.prefix(maxFiles))
        }
        return fileIds
    }

    private static func processFile(
        fileId: String,
        dataDir: URL,
        asrManager: AsrManager,
        ctcModels: CtcModels,
        spotter: CtcKeywordSpotter,
        keywordsMode: KeywordsMode,
        useConstrainedCTC: Bool
    ) async throws -> [String: Any]? {
        let wavFile = dataDir.appendingPathComponent("\(fileId).wav")
        let dictionaryFile = dataDir.appendingPathComponent("\(fileId).dictionary.txt")
        let keywordsFile = dataDir.appendingPathComponent("\(fileId).keywords.txt")
        let checkFile = dataDir.appendingPathComponent("\(fileId).check.txt")
        let textFile = dataDir.appendingPathComponent("\(fileId).text.txt")

        let fm = FileManager.default
        guard fm.fileExists(atPath: wavFile.path),
            fm.fileExists(atPath: dictionaryFile.path)
        else {
            return nil
        }

        // Load dictionary words (chunk-level keywords that actually appear in this chunk)
        let dictionaryContent = try String(contentsOf: dictionaryFile, encoding: .utf8)
        let dictionaryWords =
            dictionaryContent
            .components(separatedBy: .newlines)
            .map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
            .filter { !$0.isEmpty }

        // Determine vocabulary words based on keywords mode
        // - chunk: Use dictionary.txt (chunk-level keywords)
        // - file: Use keywords.txt (file-level keywords, all keywords for entire file)
        let vocabularyWords: [String]
        if keywordsMode == .file, fm.fileExists(atPath: keywordsFile.path),
            let keywordsContent = try? String(contentsOf: keywordsFile, encoding: .utf8)
        {
            let words =
                keywordsContent
                .components(separatedBy: .newlines)
                .map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
                .filter { !$0.isEmpty }
            vocabularyWords = words.isEmpty ? dictionaryWords : words
        } else {
            vocabularyWords = dictionaryWords
        }

        // Load check words for scoring
        // Always use dictionary words for scoring since those are the ones that actually appear in this chunk
        let checkWords: [String]
        if fm.fileExists(atPath: checkFile.path),
            let checkContent = try? String(contentsOf: checkFile, encoding: .utf8)
        {
            let words =
                checkContent
                .components(separatedBy: .newlines)
                .map { $0.trimmingCharacters(in: .whitespacesAndNewlines) }
                .filter { !$0.isEmpty }
            checkWords = words.isEmpty ? dictionaryWords : words
        } else {
            checkWords = dictionaryWords
        }

        // Load reference text
        let referenceRaw =
            (try? String(contentsOf: textFile, encoding: .utf8))?.trimmingCharacters(in: .whitespacesAndNewlines) ?? ""

        // Get audio samples
        let audioFile = try AVAudioFile(forReading: wavFile)
        let audioLength = Double(audioFile.length) / audioFile.processingFormat.sampleRate
        let format = audioFile.processingFormat
        let frameCount = AVAudioFrameCount(audioFile.length)

        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            throw NSError(
                domain: "CtcEarningsBenchmark", code: 1,
                userInfo: [NSLocalizedDescriptionKey: "Failed to create audio buffer"])
        }
        try audioFile.read(into: buffer)

        // Resample to 16kHz
        let converter = AudioConverter()
        let samples = try converter.resampleBuffer(buffer)

        let startTime = Date()

        // 1. TDT transcription for low WER
        let tdtResult = try await asrManager.transcribe(wavFile)

        // Skip files where TDT returns empty (some audio files cause model issues)
        if tdtResult.text.isEmpty {
            print("  SKIPPED: TDT returned empty transcription")
            return nil
        }

        // Debug: Show TDT word timings if available
        let debugTimings = ProcessInfo.processInfo.environment["DEBUG_TIMINGS"] == "1"
        if debugTimings, let tokenTimings = tdtResult.tokenTimings, !tokenTimings.isEmpty {
            print("  TDT Token Count: \(tokenTimings.count)")
            // Show raw tokens around 8.0-12.0s (where "Bose" should be - reference says "Bose, just, all I said")
            print("  TDT Tokens 7.0-13.0s:")
            for timing in tokenTimings {
                if timing.startTime >= 7.0 && timing.startTime <= 13.0 {
                    print(
                        "    [\(String(format: "%.2f", timing.startTime))-\(String(format: "%.2f", timing.endTime))s] \"\(timing.token)\" (conf: \(String(format: "%.2f", timing.confidence)))"
                    )
                }
            }
        }

        // 2. Build custom vocabulary for CTC keyword spotting
        // Load using simple format which supports aliases: "word: alias1, alias2, ..."
        // Then post-process to add CTC token IDs
        let vocabFileURL: URL
        if keywordsMode == .file, fm.fileExists(atPath: keywordsFile.path) {
            vocabFileURL = keywordsFile
        } else {
            vocabFileURL = dictionaryFile
        }

        // Load vocabulary with alias support
        let loadedVocab = try CustomVocabularyContext.loadFromSimpleFormat(from: vocabFileURL)

        // Post-process: add CTC token IDs for each term
        var vocabTerms: [CustomVocabularyTerm] = []
        for term in loadedVocab.terms {
            let tokenIds = tokenize(term.text, vocabulary: ctcModels.vocabulary)
            if !tokenIds.isEmpty {
                let termWithTokens = CustomVocabularyTerm(
                    text: term.text,
                    weight: term.weight,
                    aliases: term.aliases,
                    tokenIds: nil,
                    ctcTokenIds: tokenIds
                )
                vocabTerms.append(termWithTokens)
            }
        }
        let customVocab = CustomVocabularyContext(terms: vocabTerms)

        // 3. CTC keyword spotting for high recall dictionary detection
        let spotResult = try await spotter.spotKeywordsWithLogProbs(
            audioSamples: samples,
            customVocabulary: customVocab,
            minScore: nil
        )

        // Debug: Show CTC detections with timestamps
        if debugTimings && !spotResult.detections.isEmpty {
            print("  CTC Detections:")
            for detection in spotResult.detections {
                print(
                    "    [\(String(format: "%.2f", detection.startTime))-\(String(format: "%.2f", detection.endTime))s] \"\(detection.term.text)\" (score: \(String(format: "%.2f", detection.score)))"
                )
            }
        }

        // 4. Post-process: Use VocabularyRescorer with timestamp-based matching (NeMo CTC-WS)
        // Set USE_TIMESTAMP_RESCORING=1 to use timestamp-based matching (default)
        // Set USE_TIMESTAMP_RESCORING=0 to use legacy string-similarity based matching
        let useRescorer = ProcessInfo.processInfo.environment["NO_CTC_RESCORING"] != "1"
        let hypothesis: String
        if useRescorer {
            // Vocabulary-size-aware thresholds
            let vocabSize = vocabularyWords.count
            let vocabConfig = ContextBiasingConstants.rescorerConfig(forVocabSize: vocabSize)

            let rescorerConfig = VocabularyRescorer.Config.default

            let ctcModelDir = CtcModels.defaultCacheDirectory(for: ctcModels.variant)
            let rescorer = try await VocabularyRescorer.create(
                spotter: spotter,
                vocabulary: customVocab,
                config: rescorerConfig,
                ctcModelDirectory: ctcModelDir
            )

            // Adjust similarity threshold based on vocabulary size
            // Key insight: minSimilarity is the main lever for WER vs Recall trade-off
            // 0.50 = too permissive (WER 24.75%, Recall 81.5%)
            // 0.70 = too conservative (WER 16.69%, Recall 74.5%)
            // 0.60 = balanced target
            //
            // Environment variable overrides for tuning experiments:
            // MIN_SIMILARITY=0.55 CBW=2.8 fluidaudiocli ctc-earnings-benchmark ...
            let defaultMinSimilarity: Float = vocabConfig.minSimilarity
            let defaultCbw: Float = vocabConfig.cbw

            let minSimilarity: Float =
                ProcessInfo.processInfo.environment["MIN_SIMILARITY"]
                .flatMap { Float($0) } ?? defaultMinSimilarity
            let cbw: Float =
                ProcessInfo.processInfo.environment["CBW"]
                .flatMap { Float($0) } ?? defaultCbw

            if useConstrainedCTC, let tokenTimings = tdtResult.tokenTimings, !tokenTimings.isEmpty {
                // Use constrained CTC rescoring (string similarity first, then constrained DP)
                let rescoreResult = rescorer.ctcTokenRescore(
                    transcript: tdtResult.text,
                    tokenTimings: tokenTimings,
                    logProbs: spotResult.logProbs,
                    frameDuration: spotResult.frameDuration,
                    cbw: cbw,
                    marginSeconds: 0.5,
                    minSimilarity: minSimilarity
                )
                hypothesis = rescoreResult.text
            } else {
                hypothesis = tdtResult.text  // No rescoring (missing token timings or --no-constrained-ctc)
            }
        } else {
            hypothesis = tdtResult.text  // Baseline: no CTC corrections
        }

        let processingTime = Date().timeIntervalSince(startTime)

        // Normalize texts
        let referenceNormalized = TextNormalizer.normalize(referenceRaw)
        let hypothesisNormalized = TextNormalizer.normalize(hypothesis)

        let referenceWords = referenceNormalized.components(separatedBy: CharacterSet.whitespacesAndNewlines).filter {
            !$0.isEmpty
        }
        let hypothesisWords = hypothesisNormalized.components(separatedBy: CharacterSet.whitespacesAndNewlines).filter {
            !$0.isEmpty
        }

        // Calculate WER
        let wer: Double
        if referenceWords.isEmpty {
            wer = hypothesisWords.isEmpty ? 0.0 : 1.0
        } else {
            wer = calculateWER(reference: referenceWords, hypothesis: hypothesisWords)
        }

        // Count dictionary detections (CTC + hypothesis fallback)
        // Use checkWords for scoring (subset of dictionary if .check.txt exists)
        let minCtcScore: Float = -15.0  // Permissive threshold for detection
        var dictFound = 0
        var detectionDetails: [[String: Any]] = []
        var ctcFoundWords: Set<String> = []
        let checkWordsLowerSet = Set(checkWords.map { $0.lowercased() })

        // 1. CTC detections (deduplicate - only count each word once, only if in checkWords)
        for detection in spotResult.detections {
            let detail: [String: Any] = [
                "word": detection.term.text,
                "score": round(Double(detection.score) * 100) / 100,
                "startTime": round(detection.startTime * 100) / 100,
                "endTime": round(detection.endTime * 100) / 100,
                "source": "ctc",
            ]
            detectionDetails.append(detail)

            if detection.score >= minCtcScore {
                let wordLower = detection.term.text.lowercased()
                // Only count if word is in checkWords and not already counted
                if checkWordsLowerSet.contains(wordLower) && !ctcFoundWords.contains(wordLower) {
                    dictFound += 1
                    ctcFoundWords.insert(wordLower)
                }
            }
        }

        // 2. Fallback: check hypothesis for check words not found by CTC
        let hypothesisLower = hypothesisNormalized.lowercased()
        for word in checkWords {
            let wordLower = word.lowercased()
            if !ctcFoundWords.contains(wordLower) {
                // Check if word appears as whole word in hypothesis (avoid substring false positives)
                let pattern = "\\b\(NSRegularExpression.escapedPattern(for: wordLower))\\b"
                if let regex = try? NSRegularExpression(pattern: pattern, options: []),
                    regex.firstMatch(
                        in: hypothesisLower, options: [],
                        range: NSRange(hypothesisLower.startIndex..., in: hypothesisLower)) != nil
                {
                    dictFound += 1
                    ctcFoundWords.insert(wordLower)
                    let detail: [String: Any] = [
                        "word": word,
                        "score": 0.0,
                        "startTime": 0.0,
                        "endTime": 0.0,
                        "source": "hypothesis",
                    ]
                    detectionDetails.append(detail)
                }
            }
        }

        // 3. Compute precision/recall metrics
        // For each check word, check if it's in reference AND hypothesis
        let referenceLower = referenceNormalized.lowercased()
        var truePositives = 0
        var falsePositives = 0
        var falseNegatives = 0

        for word in checkWords {
            let wordLower = word.lowercased()
            let pattern = "\\b\(NSRegularExpression.escapedPattern(for: wordLower))\\b"

            let inReference: Bool
            let inHypothesis: Bool

            if let regex = try? NSRegularExpression(pattern: pattern, options: []) {
                inReference =
                    regex.firstMatch(
                        in: referenceLower, options: [],
                        range: NSRange(referenceLower.startIndex..., in: referenceLower)) != nil
                inHypothesis =
                    regex.firstMatch(
                        in: hypothesisLower, options: [],
                        range: NSRange(hypothesisLower.startIndex..., in: hypothesisLower)) != nil
            } else {
                inReference = referenceLower.contains(wordLower)
                inHypothesis = hypothesisLower.contains(wordLower)
            }

            if inReference && inHypothesis {
                truePositives += 1
            } else if inHypothesis && !inReference {
                falsePositives += 1
            } else if inReference && !inHypothesis {
                falseNegatives += 1
            }
            // Note: if neither in reference nor hypothesis, it's a true negative (not counted)
        }

        let result: [String: Any] = [
            "fileId": fileId,
            "reference": referenceRaw,
            "hypothesis": hypothesis,
            "referenceNormalized": referenceNormalized,
            "hypothesisNormalized": hypothesisNormalized,
            "wer": round(wer * 10000) / 100,
            "dictFound": dictFound,
            "dictTotal": checkWords.count,
            "truePositives": truePositives,
            "falsePositives": falsePositives,
            "falseNegatives": falseNegatives,
            "audioLength": round(audioLength * 100) / 100,
            "processingTime": round(processingTime * 1000) / 1000,
            "ctcDetections": detectionDetails,
        ]
        return result
    }

    /// Simple tokenization using vocabulary lookup
    private static func tokenize(_ text: String, vocabulary: [Int: String]) -> [Int] {
        // Build reverse vocabulary (token -> id)
        var tokenToId: [String: Int] = [:]
        for (id, token) in vocabulary {
            tokenToId[token] = id
        }

        let normalizedText = text.lowercased()
        var result: [Int] = []
        var position = normalizedText.startIndex
        var isWordStart = true

        while position < normalizedText.endIndex {
            var matched = false
            let remaining = normalizedText.distance(from: position, to: normalizedText.endIndex)
            var matchLength = min(20, remaining)

            while matchLength > 0 {
                let endPos = normalizedText.index(position, offsetBy: matchLength)
                let substring = String(normalizedText[position..<endPos])

                // Try with SentencePiece prefix for word start
                let withPrefix = isWordStart ? "‚ñÅ" + substring : substring

                if let tokenId = tokenToId[withPrefix] {
                    result.append(tokenId)
                    position = endPos
                    isWordStart = false
                    matched = true
                    break
                } else if let tokenId = tokenToId[substring] {
                    result.append(tokenId)
                    position = endPos
                    isWordStart = false
                    matched = true
                    break
                }

                matchLength -= 1
            }

            if !matched {
                let char = normalizedText[position]
                if char == " " {
                    isWordStart = true
                    position = normalizedText.index(after: position)
                } else {
                    // Unknown character - skip
                    position = normalizedText.index(after: position)
                    isWordStart = false
                }
            }
        }

        return result
    }

    /// Apply CTC keyword corrections to TDT transcription using multiple strategies:
    /// 1. Fuzzy matching (for words that are phonetically similar)
    /// 2. Context pattern matching (for "this is X" type patterns)
    /// 3. Proper noun replacement (for names after common patterns)
    private static func applyKeywordCorrections(
        tdtResult: ASRResult,
        detections: [CtcKeywordSpotter.KeywordDetection],
        minScore: Float
    ) -> String {
        // Filter detections by score
        let validDetections = detections.filter { $0.score >= minScore }
        guard !validDetections.isEmpty else {
            return tdtResult.text
        }

        var text = tdtResult.text
        var usedDetections: Set<String> = []

        // PASS 1: Fuzzy matching for phonetically similar words
        for detection in validDetections {
            let keyword = detection.term.text
            let keywordLower = keyword.lowercased()
            let keywordParts = keywordLower.components(separatedBy: " ").filter { !$0.isEmpty }

            let words = text.components(separatedBy: .whitespacesAndNewlines).filter { !$0.isEmpty }

            // Handle multi-word keywords
            if keywordParts.count > 1 {
                for i in 0..<(words.count - keywordParts.count + 1) {
                    var allMatch = true
                    var matchedWords: [String] = []

                    for j in 0..<keywordParts.count {
                        let wordClean = words[i + j].trimmingCharacters(in: .punctuationCharacters).lowercased()
                        if isSimilar(wordClean, keywordParts[j]) {
                            matchedWords.append(words[i + j])
                        } else {
                            allMatch = false
                            break
                        }
                    }

                    if allMatch && !matchedWords.isEmpty {
                        let originalPhrase = matchedWords.joined(separator: " ")
                        let replacement = matchCase(keyword, to: matchedWords[0])
                        text = text.replacingOccurrences(of: originalPhrase, with: replacement)
                        usedDetections.insert(keyword)
                        break
                    }
                }
            } else {
                // Single word keyword
                for word in words {
                    let wordClean = word.trimmingCharacters(in: .punctuationCharacters).lowercased()
                    guard !wordClean.isEmpty else { continue }

                    if isSimilar(wordClean, keywordLower) && wordClean != keywordLower {
                        let replacement = matchCase(keyword, to: word)
                        text = text.replacingOccurrences(of: word, with: replacement)
                        usedDetections.insert(keyword)
                        break
                    }
                }
            }
        }

        // PASS 2: Context pattern matching - specifically for "this is X" pattern
        // Only replace if keyword is NOT already in the text
        for detection in validDetections {
            let keyword = detection.term.text
            guard !usedDetections.contains(keyword) else { continue }

            let keywordLower = keyword.lowercased()

            // Skip if keyword already exists in text (case-insensitive)
            if text.lowercased().contains(keywordLower) {
                usedDetections.insert(keyword)  // Mark as handled
                continue
            }

            // Check if keyword looks like a proper noun (starts with uppercase)
            let isProperNoun =
                keyword.first?.isUppercase == true
                && keyword.count >= 3
                && !stopWords.contains(keywordLower)

            guard isProperNoun else { continue }

            // Look for "this is X" pattern specifically for names
            let thisIsPattern = try? NSRegularExpression(pattern: "this is ([A-Z][a-z]+)", options: [])
            if let regex = thisIsPattern {
                let textRange = NSRange(text.startIndex..., in: text)
                if let match = regex.firstMatch(in: text, options: [], range: textRange),
                    match.numberOfRanges > 1,
                    let captureRange = Range(match.range(at: 1), in: text)
                {
                    let capturedWord = String(text[captureRange])
                    let capturedLower = capturedWord.lowercased()

                    // Skip if captured word is already a detected keyword
                    let isOtherKeyword = validDetections.contains { det in
                        det.term.text.lowercased() == capturedLower
                    }

                    if !isOtherKeyword && !stopWords.contains(capturedLower) {
                        // Similar length check
                        if abs(capturedWord.count - keyword.count) <= 3 {
                            text = text.replacingOccurrences(of: capturedWord, with: keyword)
                            usedDetections.insert(keyword)
                        }
                    }
                }
            }
        }

        return text
    }

    /// Build word timings by merging subword tokens (tokens starting with "‚ñÅ" begin new words)
    private static func buildWordTimings(
        from tokenTimings: [TokenTiming]
    ) -> [(word: String, startTime: Double, endTime: Double)] {
        var wordTimings: [(word: String, startTime: Double, endTime: Double)] = []
        var currentWord = ""
        var wordStart: Double = 0
        var wordEnd: Double = 0

        for timing in tokenTimings {
            let token = timing.token

            // Skip special tokens
            if token.isEmpty || token == "<blank>" || token == "<pad>" {
                continue
            }

            // Check if this starts a new word (has ‚ñÅ or space prefix, or is first token)
            let startsNewWord = isWordBoundary(token) || currentWord.isEmpty

            if startsNewWord && !currentWord.isEmpty {
                // Save previous word
                wordTimings.append((word: currentWord, startTime: wordStart, endTime: wordEnd))
                currentWord = ""
            }

            if startsNewWord {
                currentWord = stripWordBoundaryPrefix(token)
                wordStart = timing.startTime
            } else {
                currentWord += token
            }
            wordEnd = timing.endTime
        }

        // Save final word
        if !currentWord.isEmpty {
            wordTimings.append((word: currentWord, startTime: wordStart, endTime: wordEnd))
        }

        return wordTimings
    }

    /// Common English words that should never be replaced by keyword matching
    private static let stopWords: Set<String> = [
        // Pronouns
        "i", "you", "he", "she", "it", "we", "they", "me", "him", "her", "us", "them",
        "my", "your", "his", "its", "our", "their", "mine", "yours", "hers", "ours", "theirs",
        "this", "that", "these", "those", "who", "whom", "what", "which", "whose",
        // Common verbs
        "is", "are", "was", "were", "be", "been", "being", "am",
        "have", "has", "had", "having", "do", "does", "did", "doing", "done",
        "will", "would", "shall", "should", "may", "might", "must", "can", "could",
        "get", "got", "getting", "go", "goes", "went", "going", "gone",
        "come", "came", "coming", "see", "saw", "seen", "know", "knew", "known",
        "think", "thought", "make", "made", "take", "took", "taken", "give", "gave", "given",
        "say", "said", "tell", "told", "ask", "asked", "use", "used", "want", "wanted",
        "need", "needed", "try", "tried", "let", "put", "keep", "kept", "look", "looked",
        // Articles and determiners
        "a", "an", "the", "some", "any", "no", "every", "each", "all", "both", "few", "many",
        "much", "more", "most", "other", "another", "such",
        // Prepositions
        "in", "on", "at", "to", "for", "of", "with", "by", "from", "up", "down", "out",
        "about", "into", "over", "after", "before", "between", "under", "through", "during",
        // Conjunctions
        "and", "or", "but", "so", "yet", "nor", "if", "then", "than", "because", "while",
        "although", "unless", "since", "when", "where", "as",
        // Adverbs
        "not", "very", "just", "also", "only", "even", "still", "already", "always", "never",
        "often", "sometimes", "usually", "really", "well", "now", "here", "there", "how", "why",
        // Common words
        "yes", "no", "okay", "ok", "thank", "thanks", "please", "sorry", "hello", "hi", "bye",
        "good", "great", "bad", "new", "old", "first", "last", "long", "short", "big", "small",
        "high", "low", "right", "left", "next", "back", "same", "different", "own", "able",
        "way", "thing", "things", "time", "times", "year", "years", "day", "days", "week", "weeks",
        "part", "place", "case", "point", "fact", "end", "kind", "lot", "set",
        // Numbers
        "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten",
        "hundred", "thousand", "million", "billion",
    ]

    /// Check if two words are similar (edit distance / length ratio)
    private static func isSimilar(_ a: String, _ b: String) -> Bool {
        // Never match stop words - they're too common to be proper nouns
        if stopWords.contains(a) || stopWords.contains(b) {
            return false
        }

        let maxLen = max(a.count, b.count)
        let minLen = min(a.count, b.count)
        guard maxLen > 0, minLen >= 3 else { return false }

        // Allow more length difference for longer words
        let lenDiff = abs(a.count - b.count)
        if lenDiff > max(3, maxLen / 2) { return false }

        // Calculate edit distance
        let distance = editDistance(a, b)

        // More aggressive threshold: allow up to 40% of max length as edits
        let threshold = max(2, Int(Double(maxLen) * 0.4))

        // Also check if one is substring of other (handles "Erik" in "Ririek")
        if a.contains(b) || b.contains(a) {
            return true
        }

        // Check common prefix/suffix (handles "Heri" vs "Harry")
        let commonPrefix = commonPrefixLength(a, b)
        let commonSuffix = commonSuffixLength(a, b)
        if commonPrefix >= 2 || commonSuffix >= 2 {
            return distance <= threshold + 1
        }

        return distance <= threshold
    }

    /// Get length of common prefix
    private static func commonPrefixLength(_ a: String, _ b: String) -> Int {
        let aChars = Array(a)
        let bChars = Array(b)
        var count = 0
        for i in 0..<min(aChars.count, bChars.count) {
            if aChars[i] == bChars[i] {
                count += 1
            } else {
                break
            }
        }
        return count
    }

    /// Get length of common suffix
    private static func commonSuffixLength(_ a: String, _ b: String) -> Int {
        let aChars = Array(a.reversed())
        let bChars = Array(b.reversed())
        var count = 0
        for i in 0..<min(aChars.count, bChars.count) {
            if aChars[i] == bChars[i] {
                count += 1
            } else {
                break
            }
        }
        return count
    }

    /// Simple edit distance calculation
    private static func editDistance(_ a: String, _ b: String) -> Int {
        let a = Array(a)
        let b = Array(b)
        let m = a.count
        let n = b.count

        if m == 0 { return n }
        if n == 0 { return m }

        var dp = Array(repeating: Array(repeating: 0, count: n + 1), count: m + 1)

        for i in 0...m { dp[i][0] = i }
        for j in 0...n { dp[0][j] = j }

        for i in 1...m {
            for j in 1...n {
                if a[i - 1] == b[j - 1] {
                    dp[i][j] = dp[i - 1][j - 1]
                } else {
                    dp[i][j] = 1 + min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1]))
                }
            }
        }

        return dp[m][n]
    }

    /// Match the case pattern of the original word
    private static func matchCase(_ keyword: String, to original: String) -> String {
        let origClean = original.trimmingCharacters(in: .punctuationCharacters)

        // Check case pattern
        if origClean.first?.isUppercase == true {
            // Capitalize first letter
            return keyword.prefix(1).uppercased() + keyword.dropFirst()
        }
        return keyword
    }

    private static func calculateWER(reference: [String], hypothesis: [String]) -> Double {
        if reference.isEmpty {
            return hypothesis.isEmpty ? 0.0 : 1.0
        }

        let m = reference.count
        let n = hypothesis.count
        var dp = Array(repeating: Array(repeating: 0, count: n + 1), count: m + 1)

        for i in 0...m { dp[i][0] = i }
        for j in 0...n { dp[0][j] = j }

        for i in 1...m {
            for j in 1...n {
                if reference[i - 1] == hypothesis[j - 1] {
                    dp[i][j] = dp[i - 1][j - 1]
                } else {
                    dp[i][j] = min(dp[i - 1][j - 1], min(dp[i - 1][j], dp[i][j - 1])) + 1
                }
            }
        }

        return Double(dp[m][n]) / Double(m)
    }

    private static func printUsage() {
        let default110mPath = CtcModels.defaultCacheDirectory(for: .ctc110m).path
        let default06bPath = CtcModels.defaultCacheDirectory(for: .ctc06b).path
        print(
            """
            CTC Earnings Benchmark (TDT + CTC keyword spotting)

            Usage: fluidaudio ctc-earnings-benchmark [options]

            Options:
                --data-dir <path>     Path to earnings test dataset (auto-detected if downloaded)
                --ctc-model <path>    Path to CTC model directory (auto-detected if in standard location)
                --ctc-variant <var>   CTC model variant: '110m' (default) or '06b'
                                      - 110m: Parakeet CTC 110M (hybrid TDT+CTC, blank-dominant)
                                      - 06b: Parakeet CTC 0.6B (pure CTC, better for greedy decoding)
                --no-constrained-ctc  Disable constrained CTC rescoring (enabled by default)
                --file-id <id>        Run benchmark on a single file (e.g., "4468654_chunk39")
                --max-files <n>       Maximum number of files to process
                --output, -o <path>   Output JSON file (default: ctc_earnings_benchmark.json)
                --auto-download       Download earnings22-kws dataset if not found
                --keywords <mode>     Keywords mode: 'chunk' or 'file' (default: chunk)
                                      - chunk: Use dictionary.txt (chunk-level keywords) for vocabulary
                                      - file: Use keywords.txt (file-level keywords) for vocabulary
                                      Scoring always uses dictionary.txt (words actually in chunk)

            Default locations:
                Dataset: ~/Library/Application Support/FluidAudio/earnings22-kws/test-dataset/
                CTC Model (110m): \(default110mPath)/
                CTC Model (06b): \(default06bPath)/

            Setup:
                1. Download dataset: fluidaudio download --dataset earnings22-kws
                2. Place CTC model in standard location
                3. Run: fluidaudio ctc-earnings-benchmark

            Examples:
                # Run with auto-detected paths (110m model)
                fluidaudio ctc-earnings-benchmark

                # Run with 0.6B pure CTC model
                fluidaudio ctc-earnings-benchmark --ctc-variant 06b

                # Run with auto-download
                fluidaudio ctc-earnings-benchmark --auto-download

                # Run single file test
                fluidaudio ctc-earnings-benchmark --file-id 4468654_chunk39

                # Run with file-level keywords (larger vocabulary)
                fluidaudio ctc-earnings-benchmark --keywords file

                # Run with explicit paths
                fluidaudio ctc-earnings-benchmark \\
                    --data-dir /path/to/test-dataset \\
                    --ctc-model /path/to/parakeet-ctc-110m-coreml \\
                    --max-files 100
            """)
    }
}
#endif
